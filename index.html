<section class="section">
  <div class="container is-max-desktop">

    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This project focuses on understanding and optimizing model behavior for protein particle
            classification through systematic experimentation.
            Instead of treating performance as a single numeric outcome,
            we emphasize comparative trends across training configurations and particle classes
            to better understand how model decisions emerge.
          </p>
        </div>
      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Model & Training -->
    <h2 class="title is-3 has-text-centered">Model &amp; Training</h2>

    <!-- Task Overview -->
    <div class="content has-text-justified">
      <h3 class="title is-4">Task Overview</h3>
      <p>
        The objective of this study is to classify protein particle images into ten distinct antibody
        categories, anonymized as mAb1 through mAb10.
        Due to high visual similarity among particles, the task presents inherent ambiguity,
        making it well-suited for analyzing robustness and sensitivity in deep learning models.
      </p>
    </div>

    <!-- Optimization Section -->
    <div class="content has-text-justified">
      <h4 class="title is-5">
        Optimization of Model Configuration for Protein Particle Classification
      </h4>

      <p>
        To identify an effective configuration for protein particle classification,
        we conducted a comprehensive evaluation of approximately fifteen distinct experimental setups.
        Each setup was carefully designed by varying image normalization strategies,
        transformation pipelines, and training configurations in order to isolate
        the impact of individual design choices.
      </p>

      <p>
        Rather than relying solely on global performance averages,
        the selection process was guided by a holistic analysis of class-wise behavior.
        Classification performance was examined independently for each antibody class
        (mAb1 through mAb10), allowing us to compare relative trends in confidence,
        stability, and consistency across configurations.
      </p>

      <p>
        The most effective configuration demonstrated consistently strong behavior
        across all major evaluation criteria.
        This outcome is particularly notable given the intrinsic inter-class similarity
        of protein particles.
        The success of this configuration is primarily attributed to a training strategy
        that emphasized spatial diversity through variations in image size and orientation.
      </p>

      <p>
        By exposing the model to these controlled spatial transformations,
        the training process encouraged the development of more generalized feature representations,
        enabling reliable classification across diverse particle morphologies.
        The resulting focus of the model is further illustrated through qualitative visualization,
        such as class-wise heatmaps.
      </p>
    </div>

    <!-- Key Observations -->
    <div class="content has-text-justified">
      <h4 class="title is-5">Key Observations from Model Evaluation</h4>

      <p>
        Analysis of the best-performing configuration revealed a consistent hierarchy
        in class-level behavior.
        Certain antibody classes demonstrated comparatively stronger and more stable responses,
        while others repeatedly exhibited weaker performance trends.
        This pattern was observed not only in the optimal configuration,
        but also as a general tendency across the majority of experimental setups.
      </p>

      <p>
        These observations suggest that model difficulty is not uniformly distributed across classes.
        Instead, specific antibody categories present persistent challenges that are
        resistant to changes in training configuration.
        Such consistency highlights the importance of class-aware analysis
        when evaluating model behavior.
      </p>

      <p>
        The effectiveness of the strongest configuration can be largely attributed
        to its preprocessing pipeline, which combined random resizing,
        background unification, and orientation perturbations.
        These factors appear to play a decisive role in guiding the model
        toward learning discriminative and transferable visual features.
      </p>
    </div>

    <!-- Section B (placeholder for future expansion) -->
    <div class="content has-text-justified">
      <h4 class="title is-5">Section B</h4>
      <p>
        This section is reserved for additional analysis and interpretation.
        Future content may include deeper qualitative observations,
        comparative visual examples, or extended discussion on failure modes
        and class-specific sensitivities.
      </p>
    </div>

    <div class="content has-text-justified">
      <h4 class="title is-5">Section B Observation</h4>
      <p>
        Detailed observations related to Section B will be documented here.
        This space is intentionally structured to allow seamless expansion
        without disrupting the overall narrative or layout of the page.
      </p>
    </div>

  </div>
</section>
